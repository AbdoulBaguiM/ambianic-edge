version: '0.0.1'

# Set logging level to one of DEBUG, INFO, WARNING, ERROR
log_level: INFO

# path to the data directory
data_dir: &data_dir ./data
# !include secrets1.yaml

# Cameras and other input data sources
# Using Home Assistant conventions to ease upcoming integration
sources:
  front_door_camera: &src_front_door_cam
    uri: *secret_uri_front_door_camera
    type: video

ai_models:
#  image_classification:
#    tf_graph:
#    labels:
  image_detection: &tfm_image_detection
    model: ai_models/mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite
    labels: ai_models/coco_labels.txt
  face_detection: &tfm_face_detection
    model: ai_models/mobilenet_ssd_v2_face_quant_postprocess_edgetpu.tflite
    labels: ai_models/coco_labels.txt


# A named pipeline defines an ordered sequence of operations
# such as reading from a data source, AI model inference, saving samples and others.
pipelines:
  # sequence of piped operations for use in daytime front door watch
  daytime_front_door_watch:
    - source: *src_front_door_cam
    # - mask: svg # apply a mask to the input data
    - ai: # run ai inference on the input data
        <<: *tfm_image_detection
        confidence_threshold: 0.6
    - save_samples: # save samples from the inference results
        output_directory: *data_dir
        detections_interval: 2 # how often (in seconds) to save samples with positive label detections
        idle_interval: 60*30 #  how often (in seconds) to save samples without any detections
    # - gate: [category: person] # select the labels that will be used as input by the next ai model
    # - ai: # run the next ai model inference on data from the previous section of the pipeline
        # <<: *tfm_face_detection
        # confidence_threshold: 0.6
        # save_samples:
        # location: *data_dir
        # detections_interval: 2 # how often (in seconds) to save samples with positive label detections
      # - gate: [category: face] # select detected faces and pass on to face recognition model
      # - ai: *tfm_face_recognition
          # confidence_threshold: 0.6
      # - save_samples:
          # location: *data_dir
          # detections_interval: 2 # how often (in seconds) to save samples with positive label detections
    # - tee: # a tee splits the pipeline into independent streams, each with its own thread and copy of the input data from the previous pipe
    #   - gate: [category: vehicle]
    #   - ai: *detect_license_plate

#  nighttime_front_door_watch:
#    source: @front_door
#    -
#      mask: svg
#        - uri: ...
#      inference: @find_person_or_vehicle
#    -
#      mask:
#
#  vacation_front_door_watch:

# Policies group pipeline and are mutually exclusive.
#  Only one policy is active at a time.
#  When a specific policy is activated, all other policies are idle
# policies:
#   daytime:
#     - daytime_front_door_watch
#     - daytime_backyard_door_watch
#   nighttime:
#   vacation:

# Masks allow filtering out input signal before an AI model sees it
# masks:
  # svg mask applies an SVG graphics onto an input image
#  svg: ambianic.masks.SvgMask
#    arguments:
#      - uri # of the svg file
      # scale_to_fit indicates whether to scale the mask to fit the stream source shape
      # default True
#      - scale_to_fit
  # audio_hz_trim is a simple mask that cuts out frequency ranges from an input audio stream
  # audio_hz_trim: ambian.masks.AudioHzTrim
  #  arguments:
  #    - hz_band # lower and upper frequency range to cut out

# print a heartbeat message to the log
# helps debug why some threads hang up or go idle for a variety of potential reasons
#heartbeat:
#  interval: 60 # once a minute
