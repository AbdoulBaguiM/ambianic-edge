######################################
#  Ambianic main configuration file  #
######################################
version: '2020.12.11'

# path to the data directory
data_dir: ./data

# Set logging level to one of DEBUG, INFO, WARNING, ERROR
logging:
  file: ./data/ambianic-log.txt
  level: INFO
  # use file or console to specify corresponding log output level
  # file: INFO
  # console: WARN

# Pipeline event timeline configuration
timeline:
  event_log: ./data/timeline-event-log.yaml

# Cameras and other input data sources
# Using Home Assistant conventions to ease upcoming integration
sources:

  # front_door_camera:
  #   uri: *secret_uri_front_door_camera
  #   type: video, audio, or auto
  #   type: video
  #   live: true

  # direct support for raspberry picamera
  picamera:
    uri: picamera
    type: video
    live: true

  # local video device integration example
  webcam:
    uri: /dev/video0
    type: video
    live: true

  recorded_cam_feed:
    uri: file:///workspace/tests/pipeline/avsource/test2-cam-person1.mkv
#    uri: rtsp://admin:121174l2ll74@192.168.86.131:554/Streaming/Channels/101
#    uri: http://192.168.86.29/cgi-bin/api.cgi?cmd=Snap&channel=0&rs=wuuPhkmUCeI9WG7C&user=admin&password=121174l2ll74
#    type: video
#    live: true

ai_models:
  image_detection:
    model:
      tflite: ai_models/mobilenet_ssd_v2_coco_quant_postprocess.tflite
      edgetpu: ai_models/mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite
    labels: ai_models/coco_labels.txt
  face_detection:
    model:
      tflite: ai_models/mobilenet_ssd_v2_face_quant_postprocess.tflite
      edgetpu: ai_models/mobilenet_ssd_v2_face_quant_postprocess_edgetpu.tflite
    labels: ai_models/coco_labels.txt
    top_k: 2
  fall_detection:
    model:
      tflite: ai_models/posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite
      edgetpu: ai_models/posenet_mobilenet_v1_075_721_1281_quant_decoder_edgetpu.tflite
    labels: ai_models/pose_labels.txt


# A named pipeline defines an ordered sequence of operations
# such as reading from a data source, AI model inference, saving samples and others.
pipelines:
   # Pipeline names could be descriptive, e.g. front_door_watch or entry_room_watch.
   area_watch:
     - source: picamera
     - detect_objects: # run ai inference on the input data
        ai_model: image_detection
        confidence_threshold: 0.6
     - save_detections: # save samples from the inference results
        positive_interval: 60 # how often (in seconds) to save samples with ANY results above the confidence threshold
        idle_interval: 6000 # how often (in seconds) to save samples with NO results above the confidence threshold
     - detect_falls: # look for falls
        ai_model: fall_detection
        confidence_threshold: 0.6
     - save_detections: # save samples from the inference results
        positive_interval: 10
        idle_interval: 600